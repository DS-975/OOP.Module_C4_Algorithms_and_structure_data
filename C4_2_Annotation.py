C4.2. О-нотация

В повседневной жизни мы так или иначе пользуемся алгоритмами: алгоритмы приготовления ужина, алгоритм составления пути от дома до любимого места в городе, алгоритм уборки квартиры и многие другие. Мы, конечно, обычно их так не называем, но, в общем-то, выполняем некоторую последовательность действий.

Любую цель из представленных выше (ужин, местоположение в городе, чистая квартира) можно выполнить большим количеством способов. И, как правило, мы выбираем наиболее эффективный способ это сделать. Эффективность уборки квартиры напрямую связана с количеством времени, которое было затрачено на нее. Чем быстрее мы выполним все запланированные действия, тем более эффективен будет наш «алгоритм». С другой стороны, приготовление ужина неизбежно связано с количеством загрязненной посуды во время готовки. Большое её количество будет нас расстраивать, потому что мытье посуды обычно входит в план приготовления ужина. :) И пусть время здесь уже не играет значимую роль, если нет задачи приготовить как можно быстрее, очень весомым становятся вот такие «побочные» эффекты наших действий.

Разрезая круглую пиццу по кусочку от центра, мы должны сделать n разрезов, если мы хотим получить n кусочков. Однако можно пиццу резать каждый раз вдоль диаметра (от края до края). И пусть мы всегда получим четное количество кусочков, но сможем сделать это намного быстрее!

Задание 4.2.1
1/1 point (graded)
Сравните количество разрезов пиццы для получения 16 кусочков при использовании одного и другого способа. Найдите отношение p/q, если p — количество разрезов от центра, q — количество разрезов по диаметру.
2
  верно 
 
Show answer
Отправить
Some problems have options such as save, reset, hints, or show answer. These options follow the Submit button.
С алгоритмами, которые реализуют программисты, происходит абсолютно тоже самое, только наши «инструменты» — не кастрюли и швабры, а переменные и данные. По аналогии, критериями эффективности или, иначе, сложности алгоритмов являются временной и пространственный.

Временная сложность алгоритма говорит нам о том, какое количество времени может потребоваться для выполнения этого алгоритма. И, естественно, она зависит от размера входных данных — точно также, как уборка от площади квартиры.

Пространственная сложность алгоритма связана с количеством памяти, которое он использует в ходе своей работы. Здесь работает та же аналогия с приготовлением ужина — зависимость от количества посуды, которая загрязняется из-за готовки. Здесь и далее в основном будем говорить о временной сложности алгоритмов и в некоторых случаях затрагивать пространственную, когда это будет необходимо.

Алгоритмы различной сложности
Самый простой, самый эффективный алгоритм, к которому все стремятся, — это константный алгоритм.

Константным, или постоянным по времени, называется алгоритм, который выполняет необходимое действие всегда за одинаковое количество времени (с точностью до небольшого множителя, вызванного техническими характеристиками вычислительной машины).

К таким «алгоритмам» относят очень простые операции:

присваивание;
арифметические операции;
логические операции;
сравнение объектов;
некоторые другие действия, которые мы рассмотрим в ходе изучения модуля.
Более сложные алгоритмы уже могут зависеть от количества входных данных. Например, если вам нужно найти максимальный элемент в списке, то самый простой способ — пройтись по всем элементам списка. Здесь константного времени уже не хватит, потому что велика разница между поиском максимального среди 3 элементов или среди 3 миллионов элементов.

Однако больше ни от чего такой поиск не зависит — чем больше элементов, тем больше времени нужно, и, более того, количество времени возрастает в тоже самое количество раз, как и размер списка. Такие алгоритмы называют линейными. Если продолжать аналогию с ужином, то «пространственная сложность» приготовления ужина зависит от количества гостей на нем. Чем больше гостей, тем больше тарелок придется мыть после него.

Бывают ситуации, когда алгоритмы могут работать быстрее, чем линейные: самые распространенные — это логарифмические алгоритмы. Их название напрямую связано с тем, как возрастает временная сложность алгоритма с ростом размера входных данных.

В computer science принято основание логарифма считать равным двум (двоичный логарифм), если не сказано иное. Здесь можно вспомнить про логарифмы.

Удивительно, но и вполне естественно, что логарифмические алгоритмы также встречаются в бытовой сфере. Например, вам нужно разрезать лист А4 на 16 частей. Можно сделать разметку и отрезать кусочек за кусочком — такой алгоритм будет линейным, но можно разрезать пополам, потом сложить их и разрезать сразу оба. Получившиеся четверти снова сложить и снова разрезать, но уже сразу 4 штуки и т. д. — это и есть логарифмический алгоритм.

Задание 4.2.2
1/1 point (graded)
Во сколько раз быстрее будет разрезать листок А4 «логарифмически», чем «линейно»? В ответ запишите отношение (округлив до целого, если необходимо) p/q, где p — количество разрезов по кусочкам, а q — количество разрезов, накладывая части друг на друга после каждого разреза.

img

В линейном случае предполагается, что каждый отрезок разрезается отдельно.

img

6
  верно 
 
Hint
Show answer
Отправить
Some problems have options such as save, reset, hints, or show answer. These options follow the Submit button.
Естественно, бывают алгоритмы и сложнее. Линейный алгоритм является частным случаем полиномиальных алгоритмов, а всех их объединяет, что для обработки n объектов входных данных (чисел, например) требуется n^k операций.

img  Пример

Чтобы расставить книги в алфавитном порядке нам понадобится примерно n^2 операций.

Почему n^2? Давайте попробуем посчитать на примере расстановки 10 книг в алфавитном порядке (слева направо):

Сначала мы должны найти самую первую книгу: просматриваем одну за одной, чтобы найти, какая должна стоять первой. Выбираем любую из 10 и сравниваем с каждой, чтобы убедиться, что она должна быть первой, или установить, что сравниваемая книга должна стоять левее. Всего проводим 9 сравнений. Ставим ее на полку.
Берем произвольно следующую книгу (вторую) из оставшихся девяти. Для нее проводим такую же операцию — сравниваем с оставшимися 8. Таким образом имеем еще 8 сравнений.
Берем N-ную книгу из 10. Предполагается, что к этому моменту мы уже поставили на полку N-1 книгу. Для сравнения c N-ой у нас останется 10-N книг. А значит, столько же сравнений.
И, наконец, когда остается только 2 книги нам нужно сделать только одно сравнение.
И для последней книги мы не должны ничего сравнивать, поэтому просто ставим на полку — имеем 0 сравнений. После этого завершаем работу «алгоритма».
Проведем расчёты общего количества сравнений. Имеется N операций взятия книги и сравнения с оставшимися. В нашем примере — это десять — столько раз мы берем произвольную книгу из «кучи» и сравниваем с нерасставленными. Сложим все сравнения, которые мы делали все эти 10 раз:

9 + 8 + 7 + 6 + 5 + 4 + 3 + 2 + 1 + 0

В математике такая последовательность чисел называется арифметической прогрессией (каждый последующий член последовательности отличается от предыдущего на постоянное число). Существует формула для нахождения суммы членов арифметической прогрессии: мы должны найти среднее арифметическое первого и последнего членов прогрессии и умножить на количество всех членов.

Юный Карл Гаусс (известнейший математик) решил похожую задачку еще в 10 лет! Здесь можно почитать, как он это сделал.

Для нашей арифметической прогрессии имеем:

(9 + 0) / 2 * 10 = 45

Это общее количество операций сравнения, которое мы должны сделать, чтобы расставить книги в произвольном порядке. А что если у нас не 10 книг, а какое-то очень большое N? Давайте попробуем обобщить эту формулу. Здесь 9 — это общее количество книг в «куче» минус единица (потому что нам не нужно сравнивать книгу с самой собой). Для произвольно большого количества книг это число будет равно N-1. Найденное среднее арифметическое мы должны умножить на количество книг в куче согласно формуле:

(N-1 + 0) / 2 * N

Разомнем «математические» мышцы и раскроем скобки, упростив это выражение:

0.5N^2 - 0.5N

Вспомним, что мы искали что-то похожее на n^2, и мы нашли! Конечно, здесь есть множитель перед квадратом N да еще и дополнительное слагаемое. Стоит сказать, что n^2 только оценка сложности. Для анализа алгоритмов нам, как правило, не нужно знать точный множитель, а находить только общую зависимость от входных данных.

Алгоритмическая троица: «О» большая, омега, тета
Становится сложно? Сейчас будет еще немного сложнее, но можем гарантировать, что это оправдано. Ведь действительно, если программист хочет писать эффективные программы, он должен понимать, по каким критериям оценивать эту эффективность. И чем точнее эти критерии, тем правильнее будет оценка сложности программы. Сначала может показаться, что в web-приложениях это не является столь необходимым, но, как можно увидеть позже, это часто играет решающую роль при работе с базой данных. Согласитесь, что гораздо быстрее выгрузить один раз все данные, а потом их обрабатывать, чем запрашивать объекты один за одним. Допустим, приехали вы в ресторан. Как будет быстрее? Заказать всё сразу (но, например, попросить приносить блюда в определенном порядке) или после завершения каждого блюда ждать официанта, чтобы заказать что-то еще, он в свою очередь должен сходить на кухню, передать заказ поварам, а также внести заказ в кассовый терминал, что потребует от него поиска вашего счёта и еще множества-множества действий. Кажется, что ответ очевиден.

Вернемся к алгоритмам.

Для оценки сложности алгоритмов вводятся 3 математические величины:

«О» большая — верхняя оценка сложности алгоритма;
«Ω» (омега) — нижняя оценка сложности;
«Θ» (тета) — точная оценка сложности.
Для одного и того же алгоритма часто бывает необходимо знать, как он работает в худшем случае, и об этом нам говорит «О» большая. Эта оценка указывает на то, хуже чего алгоритм точно не будет работать. Однако, входные данные не всегда самые плохие. И даже наоборот — встречаются данные, на которых алгоритм работает «как по маслу», может быть даже ничего с ними не делает кроме какого-то минимума. Если обратиться к предыдущему примеру с расстановкой книг. Если мы взяли случайную книгу из кучи нерасставленных, и она оказалось самой левой (в алфавитном порядке), то нам все равно нужно сравнить ее с остальными, чтобы убедиться в этом.

img

Про этот случай нам говорит нижняя оценка сложности — оценка работы алгоритма в самом лучшем из возможных случаев. И чтобы совсем не отвертеться, существуют точные оценки сложности — ни шага влево, ни шага вправо — алгоритм будет работать именно с этой сложностью. В среднем, конечно. :) Это оценка «Θ» (тета). Как правило, мы будем оценивать алгоритмы по верхней границе, с помощью «О» большой, чтобы быть уверенными, что медленнее алгоритм работать не будет. Более того, допуская некоторую математическую вольность, сложности как в среднем, так и в лучшем случае обозначать через O(n), дополнительно указывая, к какому случаю это относится.

Мы рассматривали ранее примеры различных алгоритмов — константные, логарифмические, линейные. При помощи символа «О» можно записать так называемую асимптотическую сложность алгоритма. Такое обозначение имеет сильную математическую базу, но для нас это важно тем, что это удобная краткая запись. Общепринято оценивать, насколько «проблемный» алгоритм, именно с помощью такого символа.

Сложность алгоритма	О-нотация	Примеры
Константная	O(1)	Сложение, присваивание
Логарифмическая	O(log(n))	Разрезание бумаги на части
Линейная	O(n)	Поиск максимального элемента из списка
Квадратичная	O(n^2)	Расстановка книг в алфавитном порядке
Полиномиальная	O(n^k)	Про такие алгоритмы лучше забыть
Факториальная	O(n!)	А такие наводят ужас на всех программистов
Зачем усложнять про сложности
И все-таки зачем?! Если этот вопрос вас еще до сих пор мучает, давайте посмотрим, как работают алгоритмы (в условных единицах) различной сложности с некоторыми примерами размеров данных.

Сложность/размер входных данных	n = 5	n = 10	n = 20	n = 30
O(1)	1	1	1	1
O(log(n))	2	3	4	4
O(n)	5	10	20	30
O(n^2)	25	100	400	900
O(n!)	120	3628800	243290200
8176640000	2652528598
1219106821
7601719009280
Вот это число слева внизу и пугает людей. И не зря. Представьте, что это количество микросекунд, коих в секунде миллион. Если перевести это число в миллиарды лет, то получится 8411113007. Словами это число даже проговорить сложно. Конечно, даже опытный программист вряд ли напишет алгоритм, работающий как факториал, но даже на сравнении алгоритмов линейной и квадратичной сложности видна заметная разница — аж в 30 раз, и это только на 30 объектах входных данных. И на числах становится видно, что даже небольшие (казалось бы) изменения в алгоритме могут дать заметное уменьшение сложности работы. А чтобы уметь распознавать такие тонкости, нам и нужна О-нотация!

Задание 4.2.3
1/1 point (graded)
Во сколько раз (примерно) возрастет время работы алгоритма сложностью O(n^2) по сравнению с O(n*log(n)) на входных данных размера n=10000? Ответ округлите до целого. Помните также, что логарифм берется по основанию 2.
753
  верно 
 
Show answer
Отправить
Some problems have options such as save, reset, hints, or show answer. These options follow the Submit button.
Теме О-нотации и анализу алгоритмов с помощью нее посвящено много научных трудов и исследований.

В дополнительных материалах к этой теме можно найти еще некоторые подробности, касающиеся математического фундамента, на котором стоит О-нотация, а также несколько правил по анализу алгоритмов.

